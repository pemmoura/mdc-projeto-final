{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T16:09:36.180842Z",
     "start_time": "2024-12-02T14:19:39.212991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "data_root = './'\n",
    "train_data = TabularDataset(data_root + 'train_audience.csv')\n",
    "test_data = TabularDataset(data_root + 'test_audience.csv')\n",
    "\n",
    "predictor = TabularPredictor(label='Rating').fit(train_data=train_data)\n",
    "predictions = predictor.predict(test_data)"
   ],
   "id": "4ffd78f488ce945a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ./train_audience.csv | Columns = 3 / 3 | Rows = 52416 -> 52416\n",
      "Loaded data from: ./test_audience.csv | Columns = 3 / 3 | Rows = 13105 -> 13105\n",
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20241202_141939\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.0\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       7.42 GB / 31.57 GB (23.5%)\n",
      "Disk Space Avail:   92.35 GB / 513.79 GB (18.0%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"C:\\Users\\p.moura\\Workspace\\mdc-projeto-final\\AutogluonModels\\ag-20241202_141939\"\n",
      "Train Data Rows:    52416\n",
      "Train Data Columns: 2\n",
      "Label Column:       Rating\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (5.0, 0.5, 3.52111, 1.73665)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7617.73 MB\n",
      "\tTrain Data (Original)  Memory Usage: 21.83 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Review']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 10000\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 10000 to 4783 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('object', [])       : 1 | ['Show']\n",
      "\t\t('object', ['text']) : 1 | ['Review']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    1 | ['Show']\n",
      "\t\t('category', ['text_as_category'])  :    1 | ['Review']\n",
      "\t\t('int', ['binned', 'text_special']) :   26 | ['Review.char_count', 'Review.word_count', 'Review.capital_ratio', 'Review.lower_ratio', 'Review.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 4736 | ['__nlp__.10', '__nlp__.10 10', '__nlp__.100', '__nlp__.11', '__nlp__.12', ...]\n",
      "\t48.8s = Fit runtime\n",
      "\t2 features in original data used to generate 4764 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 474.94 MB (6.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 51.48s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.04769536019536019, Train Rows: 49916, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 3.424 GB out of 7.245 GB available memory (47.262%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=2.41 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train KNeighborsUnif... Skipping this model.\n",
      "Fitting model: KNeighborsDist ...\n",
      "\tWarning: Not enough memory to safely train model. Estimated to require 3.424 GB out of 7.241 GB available memory (47.290%)... (20.000% of avail memory is the max safe size)\n",
      "\tTo force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=2.41 to avoid the error)\n",
      "\t\tTo set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "\t\tSetting \"ag.max_memory_usage_ratio\" to values above 1 may result in out-of-memory errors. You may consider using a machine with more memory as a safer alternative.\n",
      "\tNot enough memory to train KNeighborsDist... Skipping this model.\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.990804\n",
      "[2000]\tvalid_set's rmse: 0.982996\n",
      "[3000]\tvalid_set's rmse: 0.980348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.9802\t = Validation score   (-root_mean_squared_error)\n",
      "\t38.05s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.983048\n",
      "[2000]\tvalid_set's rmse: 0.97279\n",
      "[3000]\tvalid_set's rmse: 0.969275\n",
      "[4000]\tvalid_set's rmse: 0.969481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.9678\t = Validation score   (-root_mean_squared_error)\n",
      "\t43.22s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m train_data \u001B[38;5;241m=\u001B[39m TabularDataset(data_root \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_audience.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m test_data \u001B[38;5;241m=\u001B[39m TabularDataset(data_root \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_audience.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m predictor \u001B[38;5;241m=\u001B[39m \u001B[43mTabularPredictor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mRating\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m predictions \u001B[38;5;241m=\u001B[39m predictor\u001B[38;5;241m.\u001B[39mpredict(test_data)\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\utils\\decorators.py:31\u001B[0m, in \u001B[0;36munpack.<locals>._unpack_inner.<locals>._call\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     30\u001B[0m     gargs, gkwargs \u001B[38;5;241m=\u001B[39m g(\u001B[38;5;241m*\u001B[39mother_args, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1299\u001B[0m, in \u001B[0;36mTabularPredictor.fit\u001B[1;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m   1296\u001B[0m \u001B[38;5;66;03m# keep track of the fit strategy used for future calls\u001B[39;00m\n\u001B[0;32m   1297\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_strategy \u001B[38;5;241m=\u001B[39m fit_strategy\n\u001B[1;32m-> 1299\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag_fit_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mag_fit_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag_post_fit_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mag_post_fit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1301\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\tabular\\predictor\\predictor.py:1305\u001B[0m, in \u001B[0;36mTabularPredictor._fit\u001B[1;34m(self, ag_fit_kwargs, ag_post_fit_kwargs)\u001B[0m\n\u001B[0;32m   1303\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_fit\u001B[39m(\u001B[38;5;28mself\u001B[39m, ag_fit_kwargs: \u001B[38;5;28mdict\u001B[39m, ag_post_fit_kwargs: \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m   1304\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave(silent\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m# Save predictor to disk to enable prediction and training after interrupt\u001B[39;00m\n\u001B[1;32m-> 1305\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_learner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mag_fit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1306\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_post_fit_vars()\n\u001B[0;32m   1307\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_post_fit(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mag_post_fit_kwargs)\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\tabular\\learner\\abstract_learner.py:159\u001B[0m, in \u001B[0;36mAbstractTabularLearner.fit\u001B[1;34m(self, X, X_val, **kwargs)\u001B[0m\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLearner is already fit.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_fit_input(X\u001B[38;5;241m=\u001B[39mX, X_val\u001B[38;5;241m=\u001B[39mX_val, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m--> 159\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\tabular\\learner\\default_learner.py:131\u001B[0m, in \u001B[0;36mDefaultLearner._fit\u001B[1;34m(self, X, X_val, X_test, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, infer_limit, infer_limit_batch_size, verbosity, **trainer_fit_kwargs)\u001B[0m\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39meval_metric \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39meval_metric\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave()\n\u001B[1;32m--> 131\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    132\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    134\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_unlabeled\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_unlabeled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[43m    \u001B[49m\u001B[43mholdout_frac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mholdout_frac\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit_trainer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrainer_fit_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_trainer(trainer\u001B[38;5;241m=\u001B[39mtrainer)\n\u001B[0;32m    147\u001B[0m time_end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\tabular\\trainer\\auto_trainer.py:135\u001B[0m, in \u001B[0;36mAutoTrainer.fit\u001B[1;34m(self, X, y, hyperparameters, X_val, y_val, X_test, y_test, X_unlabeled, holdout_frac, num_stack_levels, core_kwargs, aux_kwargs, time_limit, infer_limit, infer_limit_batch_size, use_bag_holdout, groups, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    132\u001B[0m log_str \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m}\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    133\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m20\u001B[39m, log_str)\n\u001B[1;32m--> 135\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_multi_and_ensemble\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    136\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    137\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    138\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    141\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_unlabeled\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_unlabeled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhyperparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_stack_levels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_stack_levels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcore_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcore_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[43m    \u001B[49m\u001B[43maux_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maux_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:3238\u001B[0m, in \u001B[0;36mAbstractTrainer._train_multi_and_ensemble\u001B[1;34m(self, X, y, X_val, y_val, X_test, y_test, hyperparameters, X_unlabeled, num_stack_levels, time_limit, groups, **kwargs)\u001B[0m\n\u001B[0;32m   3236\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_rows_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(X_test)\n\u001B[0;32m   3237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_cols_train \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mlist\u001B[39m(X\u001B[38;5;241m.\u001B[39mcolumns))\n\u001B[1;32m-> 3238\u001B[0m model_names_fit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_multi_levels\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3239\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3240\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3241\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhyperparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3242\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3243\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3244\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3245\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3246\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_unlabeled\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_unlabeled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3247\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlevel_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3248\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlevel_end\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_stack_levels\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3249\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3250\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3251\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3252\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_model_names()) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   3253\u001B[0m     \u001B[38;5;66;03m# TODO v1.0: Add toggle to raise exception if no models trained\u001B[39;00m\n\u001B[0;32m   3254\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m30\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWarning: AutoGluon did not successfully train any models\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:493\u001B[0m, in \u001B[0;36mAbstractTrainer.train_multi_levels\u001B[1;34m(self, X, y, hyperparameters, X_val, y_val, X_test, y_test, X_unlabeled, base_model_names, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack, level_time_modifier, infer_limit, infer_limit_batch_size, callbacks)\u001B[0m\n\u001B[0;32m    491\u001B[0m         core_kwargs_level[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime_limit\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m core_kwargs_level\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime_limit\u001B[39m\u001B[38;5;124m\"\u001B[39m, time_limit_core)\n\u001B[0;32m    492\u001B[0m         aux_kwargs_level[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime_limit\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m aux_kwargs_level\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime_limit\u001B[39m\u001B[38;5;124m\"\u001B[39m, time_limit_aux)\n\u001B[1;32m--> 493\u001B[0m     base_model_names, aux_models \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack_new_level\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_unlabeled\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_unlabeled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbase_model_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_model_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcore_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcore_kwargs_level\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43maux_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maux_kwargs_level\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname_suffix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname_suffix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m        \u001B[49m\u001B[43minfer_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m        \u001B[49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    509\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfull_weighted_ensemble\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfull_weighted_ensemble\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[43m        \u001B[49m\u001B[43madditional_full_weighted_ensemble\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43madditional_full_weighted_ensemble\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    511\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    512\u001B[0m     model_names_fit \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m base_model_names \u001B[38;5;241m+\u001B[39m aux_models\n\u001B[0;32m    513\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_best \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m infer_limit \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(model_names_fit) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:688\u001B[0m, in \u001B[0;36mAbstractTrainer.stack_new_level\u001B[1;34m(self, X, y, models, X_val, y_val, X_test, y_test, X_unlabeled, level, base_model_names, core_kwargs, aux_kwargs, name_suffix, infer_limit, infer_limit_batch_size, full_weighted_ensemble, additional_full_weighted_ensemble)\u001B[0m\n\u001B[0;32m    686\u001B[0m     core_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname_suffix\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m core_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname_suffix\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m+\u001B[39m name_suffix\n\u001B[0;32m    687\u001B[0m     aux_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname_suffix\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m aux_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname_suffix\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m+\u001B[39m name_suffix\n\u001B[1;32m--> 688\u001B[0m core_models \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack_new_level_core\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    689\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    690\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    691\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    692\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    693\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    694\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    695\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_unlabeled\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_unlabeled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    696\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    697\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    698\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    699\u001B[0m \u001B[43m    \u001B[49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfer_limit_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    700\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbase_model_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_model_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    701\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcore_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    704\u001B[0m aux_models \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m full_weighted_ensemble:\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:835\u001B[0m, in \u001B[0;36mAbstractTrainer.stack_new_level_core\u001B[1;34m(self, X, y, models, X_val, y_val, X_test, y_test, X_unlabeled, level, base_model_names, fit_strategy, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001B[0m\n\u001B[0;32m    829\u001B[0m fit_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\n\u001B[0;32m    830\u001B[0m     num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_classes,\n\u001B[0;32m    831\u001B[0m     feature_metadata\u001B[38;5;241m=\u001B[39mfeature_metadata,\n\u001B[0;32m    832\u001B[0m )\n\u001B[0;32m    834\u001B[0m \u001B[38;5;66;03m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001B[39;00m\n\u001B[1;32m--> 835\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_multi\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_init\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    837\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    838\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    839\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    840\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    841\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    842\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX_unlabeled\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_unlabeled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    843\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    844\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    845\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstack_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstack_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    847\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    848\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfit_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfit_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    850\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:3170\u001B[0m, in \u001B[0;36mAbstractTrainer._train_multi\u001B[1;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, delay_bag_sets, **kwargs)\u001B[0m\n\u001B[0;32m   3168\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_repeat_start \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   3169\u001B[0m     time_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m-> 3170\u001B[0m     model_names_trained \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_multi_initial\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3171\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3172\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk_fold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk_fold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3175\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_repeats\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_repeats_initial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhyperparameter_tune_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparameter_tune_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeature_prune_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_prune_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3179\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3180\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3181\u001B[0m     n_repeat_start \u001B[38;5;241m=\u001B[39m n_repeats_initial\n\u001B[0;32m   3182\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m time_limit \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2755\u001B[0m, in \u001B[0;36mAbstractTrainer._train_multi_initial\u001B[1;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m   2753\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m bagged:\n\u001B[0;32m   2754\u001B[0m     time_ratio \u001B[38;5;241m=\u001B[39m hpo_time_ratio \u001B[38;5;28;01mif\u001B[39;00m hpo_enabled \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m-> 2755\u001B[0m     models \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_multi_fold\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2756\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2757\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhyperparameter_tune_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparameter_tune_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2758\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2759\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtime_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_split\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2760\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtime_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2761\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2762\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2763\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2764\u001B[0m     time_ratio \u001B[38;5;241m=\u001B[39m hpo_time_ratio \u001B[38;5;28;01mif\u001B[39;00m hpo_enabled \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2922\u001B[0m, in \u001B[0;36mAbstractTrainer._train_multi_fold\u001B[1;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, fit_strategy, **kwargs)\u001B[0m\n\u001B[0;32m   2919\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callback_early_stop:\n\u001B[0;32m   2920\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m models_valid\n\u001B[1;32m-> 2922\u001B[0m         models_valid \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43m_detached_train_multi_fold\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2923\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_self\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2924\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2925\u001B[0m \u001B[43m            \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2926\u001B[0m \u001B[43m            \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2927\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_start\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2928\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_split\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2929\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2930\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_limit_model_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit_model_split\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2931\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhyperparameter_tune_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparameter_tune_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2932\u001B[0m \u001B[43m            \u001B[49m\u001B[43mis_ray_worker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   2933\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2934\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2935\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m fit_strategy \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparallel\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   2936\u001B[0m     models_valid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_multi_fold_parallel(\n\u001B[0;32m   2937\u001B[0m         X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m   2938\u001B[0m         y\u001B[38;5;241m=\u001B[39my,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2945\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2946\u001B[0m     )\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:4621\u001B[0m, in \u001B[0;36m_detached_train_multi_fold\u001B[1;34m(_self, model, X, y, time_split, time_start, time_limit, time_limit_model_split, hyperparameter_tune_kwargs, is_ray_worker, kwargs)\u001B[0m\n\u001B[0;32m   4618\u001B[0m         time_start_model\u001B[38;5;241m=\u001B[39mtime\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   4619\u001B[0m         time_left\u001B[38;5;241m=\u001B[39mtime_limit\u001B[38;5;241m-\u001B[39m(time_start_model\u001B[38;5;241m-\u001B[39mtime_start)\n\u001B[1;32m-> 4621\u001B[0m model_name_trained_lst \u001B[38;5;241m=\u001B[39m \u001B[43m_self\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_single_full\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   4622\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4623\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4624\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4625\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_left\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4626\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhyperparameter_tune_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhyperparameter_tune_kwargs_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4627\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_ray_worker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_ray_worker\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   4628\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m   4629\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _self\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[0;32m   4632\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m model\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2538\u001B[0m, in \u001B[0;36mAbstractTrainer._train_single_full\u001B[1;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_test, y_test, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, errors, errors_ignore, errors_raise, is_ray_worker, **kwargs)\u001B[0m\n\u001B[0;32m   2534\u001B[0m         bagged_model_fit_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_bagged_model_fit_kwargs(\n\u001B[0;32m   2535\u001B[0m             k_fold\u001B[38;5;241m=\u001B[39mk_fold, k_fold_start\u001B[38;5;241m=\u001B[39mk_fold_start, k_fold_end\u001B[38;5;241m=\u001B[39mk_fold_end, n_repeats\u001B[38;5;241m=\u001B[39mn_repeats, n_repeat_start\u001B[38;5;241m=\u001B[39mn_repeat_start\n\u001B[0;32m   2536\u001B[0m         )\n\u001B[0;32m   2537\u001B[0m         model_fit_kwargs\u001B[38;5;241m.\u001B[39mupdate(bagged_model_fit_kwargs)\n\u001B[1;32m-> 2538\u001B[0m     model_names_trained \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_and_save\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2539\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2540\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2541\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2542\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2543\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2544\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2545\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2546\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX_unlabeled\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_unlabeled\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2547\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstack_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstack_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2548\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2549\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcompute_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2550\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtotal_resources\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_resources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2551\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2552\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors_ignore\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors_ignore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2553\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors_raise\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors_raise\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2554\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_ray_worker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_ray_worker\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2555\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_fit_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2556\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2557\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks \u001B[38;5;129;01mand\u001B[39;00m check_callbacks:\n\u001B[0;32m   2558\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callbacks_after_fit(model_names\u001B[38;5;241m=\u001B[39mmodel_names_trained, stack_name\u001B[38;5;241m=\u001B[39mstack_name, level\u001B[38;5;241m=\u001B[39mlevel)\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:2106\u001B[0m, in \u001B[0;36mAbstractTrainer._train_and_save\u001B[1;34m(self, X, y, model, X_val, y_val, X_test, y_test, X_pseudo, y_pseudo, time_limit, stack_name, level, compute_score, total_resources, errors, errors_ignore, errors_raise, is_ray_worker, **model_fit_kwargs)\u001B[0m\n\u001B[0;32m   2104\u001B[0m exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   2105\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 2106\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train_single\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_fit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2108\u001B[0m     fit_end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   2109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight_evaluation:\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\trainer\\abstract_trainer.py:1993\u001B[0m, in \u001B[0;36mAbstractTrainer._train_single\u001B[1;34m(self, X, y, model, X_val, y_val, X_test, y_test, total_resources, **model_fit_kwargs)\u001B[0m\n\u001B[0;32m   1977\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_train_single\u001B[39m(\n\u001B[0;32m   1978\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   1979\u001B[0m     X: pd\u001B[38;5;241m.\u001B[39mDataFrame,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1987\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_fit_kwargs,\n\u001B[0;32m   1988\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m AbstractModel:\n\u001B[0;32m   1989\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1990\u001B[0m \u001B[38;5;124;03m    Trains model but does not add the trained model to this Trainer.\u001B[39;00m\n\u001B[0;32m   1991\u001B[0m \u001B[38;5;124;03m    Returns trained model object.\u001B[39;00m\n\u001B[0;32m   1992\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1993\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_val\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_val\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtotal_resources\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_resources\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_fit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1994\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\core\\models\\abstract\\abstract_model.py:925\u001B[0m, in \u001B[0;36mAbstractModel.fit\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    923\u001B[0m         logger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mWarning: Model has no time left to train, skipping model... (Time Left = \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime_limit\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.1f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124ms)\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    924\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m TimeLimitExceeded\n\u001B[1;32m--> 925\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    926\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m out \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    927\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\autogluon\\tabular\\models\\rf\\rf_model.py:214\u001B[0m, in \u001B[0;36mRFModel._fit\u001B[1;34m(self, X, y, num_cpus, time_limit, sample_weight, **kwargs)\u001B[0m\n\u001B[0;32m    212\u001B[0m         params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_estimators\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m n_estimators\n\u001B[0;32m    213\u001B[0m         model \u001B[38;5;241m=\u001B[39m model_cls(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[1;32m--> 214\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;28mlen\u001B[39m(n_estimator_increments) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m    216\u001B[0m     time_elapsed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m time_train_start, \u001B[38;5;241m0.001\u001B[39m)  \u001B[38;5;66;03m# avoid it being too small and being truncated to 0\u001B[39;00m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    478\u001B[0m trees \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    479\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_estimator(append\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, random_state\u001B[38;5;241m=\u001B[39mrandom_state)\n\u001B[0;32m    480\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_more_estimators)\n\u001B[0;32m    481\u001B[0m ]\n\u001B[0;32m    483\u001B[0m \u001B[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001B[39;00m\n\u001B[0;32m    484\u001B[0m \u001B[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001B[39;00m\n\u001B[0;32m    485\u001B[0m \u001B[38;5;66;03m# making threading more efficient than multiprocessing in\u001B[39;00m\n\u001B[0;32m    486\u001B[0m \u001B[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001B[39;00m\n\u001B[0;32m    487\u001B[0m \u001B[38;5;66;03m# parallel_backend contexts set at a higher level,\u001B[39;00m\n\u001B[0;32m    488\u001B[0m \u001B[38;5;66;03m# since correctness does not rely on using threads.\u001B[39;00m\n\u001B[1;32m--> 489\u001B[0m trees \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    490\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    491\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    492\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mthreads\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_parallel_build_trees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_samples_bootstrap\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmissing_values_in_feature_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    506\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    507\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrees\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    508\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    510\u001B[0m \u001B[38;5;66;03m# Collect newly grown trees\u001B[39;00m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mextend(trees)\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     69\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     70\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     71\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     73\u001B[0m )\n\u001B[1;32m---> 74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\joblib\\parallel.py:2007\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   2001\u001B[0m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[0;32m   2002\u001B[0m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[0;32m   2003\u001B[0m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[0;32m   2004\u001B[0m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[0;32m   2005\u001B[0m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[1;32m-> 2007\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\joblib\\parallel.py:1650\u001B[0m, in \u001B[0;36mParallel._get_outputs\u001B[1;34m(self, iterator, pre_dispatch)\u001B[0m\n\u001B[0;32m   1647\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[0;32m   1649\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[1;32m-> 1650\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retrieve()\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[0;32m   1653\u001B[0m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[0;32m   1654\u001B[0m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[0;32m   1655\u001B[0m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[0;32m   1656\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\joblib\\parallel.py:1762\u001B[0m, in \u001B[0;36mParallel._retrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1757\u001B[0m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[0;32m   1758\u001B[0m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[0;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m   1760\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mget_status(\n\u001B[0;32m   1761\u001B[0m         timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout) \u001B[38;5;241m==\u001B[39m TASK_PENDING)):\n\u001B[1;32m-> 1762\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1763\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m   1765\u001B[0m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[0;32m   1766\u001B[0m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[0;32m   1767\u001B[0m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T16:09:44.049375900Z",
     "start_time": "2024-12-02T12:54:28.371697Z"
    }
   },
   "cell_type": "code",
   "source": "predictor.leaderboard(test_data)",
   "id": "7ba440e9736b4439",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0         LightGBMLarge    0.866171   0.872466    accuracy        0.196786   \n",
       "1            LightGBMXT    0.864819   0.878378    accuracy        0.151858   \n",
       "2   WeightedEnsemble_L2    0.864819   0.878378    accuracy        0.157369   \n",
       "3              CatBoost    0.859412   0.863176    accuracy        0.102588   \n",
       "4              LightGBM    0.857722   0.866554    accuracy        0.150670   \n",
       "5        ExtraTreesGini    0.851639   0.853041    accuracy        0.310940   \n",
       "6        ExtraTreesEntr    0.851301   0.853041    accuracy        0.295508   \n",
       "7      RandomForestGini    0.850963   0.853041    accuracy        0.326426   \n",
       "8      RandomForestEntr    0.850287   0.853041    accuracy        0.316398   \n",
       "9               XGBoost    0.849273   0.862331    accuracy        0.159520   \n",
       "10       NeuralNetTorch    0.848260   0.844595    accuracy        0.040586   \n",
       "11       KNeighborsDist    0.822913   0.823480    accuracy        1.099520   \n",
       "12       KNeighborsUnif    0.822237   0.823480    accuracy        1.164535   \n",
       "13      NeuralNetFastAI    0.819196   0.832770    accuracy        0.096568   \n",
       "\n",
       "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.057531  10.820771                 0.196786                0.057531   \n",
       "1        0.040697   3.683967                 0.151858                0.040697   \n",
       "2        0.041692   3.775913                 0.005511                0.000995   \n",
       "3        0.040000  44.788380                 0.102588                0.040000   \n",
       "4        0.049327   4.737834                 0.150670                0.049327   \n",
       "5        0.091537   5.597738                 0.310940                0.091537   \n",
       "6        0.094402   5.505450                 0.295508                0.094402   \n",
       "7        0.080698   5.214043                 0.326426                0.080698   \n",
       "8        0.086539   4.018735                 0.316398                0.086539   \n",
       "9        0.031515  10.396562                 0.159520                0.031515   \n",
       "10       0.014990  11.190838                 0.040586                0.014990   \n",
       "11       0.387913   0.347521                 1.099520                0.387913   \n",
       "12       1.976378   2.077005                 1.164535                1.976378   \n",
       "13       0.035074  12.855614                 0.096568                0.035074   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           10.820771            1       True         13  \n",
       "1            3.683967            1       True          3  \n",
       "2            0.091946            2       True         14  \n",
       "3           44.788380            1       True          7  \n",
       "4            4.737834            1       True          4  \n",
       "5            5.597738            1       True          8  \n",
       "6            5.505450            1       True          9  \n",
       "7            5.214043            1       True          5  \n",
       "8            4.018735            1       True          6  \n",
       "9           10.396562            1       True         11  \n",
       "10          11.190838            1       True         12  \n",
       "11           0.347521            1       True          2  \n",
       "12           2.077005            1       True          1  \n",
       "13          12.855614            1       True         10  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.866171</td>\n",
       "      <td>0.872466</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.196786</td>\n",
       "      <td>0.057531</td>\n",
       "      <td>10.820771</td>\n",
       "      <td>0.196786</td>\n",
       "      <td>0.057531</td>\n",
       "      <td>10.820771</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.864819</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.151858</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>3.683967</td>\n",
       "      <td>0.151858</td>\n",
       "      <td>0.040697</td>\n",
       "      <td>3.683967</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.864819</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.157369</td>\n",
       "      <td>0.041692</td>\n",
       "      <td>3.775913</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.091946</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.859412</td>\n",
       "      <td>0.863176</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.102588</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>44.788380</td>\n",
       "      <td>0.102588</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>44.788380</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.857722</td>\n",
       "      <td>0.866554</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.150670</td>\n",
       "      <td>0.049327</td>\n",
       "      <td>4.737834</td>\n",
       "      <td>0.150670</td>\n",
       "      <td>0.049327</td>\n",
       "      <td>4.737834</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.851639</td>\n",
       "      <td>0.853041</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.310940</td>\n",
       "      <td>0.091537</td>\n",
       "      <td>5.597738</td>\n",
       "      <td>0.310940</td>\n",
       "      <td>0.091537</td>\n",
       "      <td>5.597738</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.851301</td>\n",
       "      <td>0.853041</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.295508</td>\n",
       "      <td>0.094402</td>\n",
       "      <td>5.505450</td>\n",
       "      <td>0.295508</td>\n",
       "      <td>0.094402</td>\n",
       "      <td>5.505450</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.850963</td>\n",
       "      <td>0.853041</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.326426</td>\n",
       "      <td>0.080698</td>\n",
       "      <td>5.214043</td>\n",
       "      <td>0.326426</td>\n",
       "      <td>0.080698</td>\n",
       "      <td>5.214043</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.850287</td>\n",
       "      <td>0.853041</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.316398</td>\n",
       "      <td>0.086539</td>\n",
       "      <td>4.018735</td>\n",
       "      <td>0.316398</td>\n",
       "      <td>0.086539</td>\n",
       "      <td>4.018735</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.849273</td>\n",
       "      <td>0.862331</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.159520</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>10.396562</td>\n",
       "      <td>0.159520</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>10.396562</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.848260</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.040586</td>\n",
       "      <td>0.014990</td>\n",
       "      <td>11.190838</td>\n",
       "      <td>0.040586</td>\n",
       "      <td>0.014990</td>\n",
       "      <td>11.190838</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.822913</td>\n",
       "      <td>0.823480</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.099520</td>\n",
       "      <td>0.387913</td>\n",
       "      <td>0.347521</td>\n",
       "      <td>1.099520</td>\n",
       "      <td>0.387913</td>\n",
       "      <td>0.347521</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.822237</td>\n",
       "      <td>0.823480</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.164535</td>\n",
       "      <td>1.976378</td>\n",
       "      <td>2.077005</td>\n",
       "      <td>1.164535</td>\n",
       "      <td>1.976378</td>\n",
       "      <td>2.077005</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.819196</td>\n",
       "      <td>0.832770</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.096568</td>\n",
       "      <td>0.035074</td>\n",
       "      <td>12.855614</td>\n",
       "      <td>0.096568</td>\n",
       "      <td>0.035074</td>\n",
       "      <td>12.855614</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T16:09:44.183626600Z",
     "start_time": "2024-12-02T12:54:44.893180Z"
    }
   },
   "cell_type": "code",
   "source": "predictor.evaluate(test_data, silent=True)",
   "id": "d8c5add4b43952f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8648191956742143,\n",
       " 'balanced_accuracy': 0.6130861853255131,\n",
       " 'mcc': 0.342164056004213,\n",
       " 'roc_auc': 0.8213768533882289,\n",
       " 'f1': 0.9244142101284959,\n",
       " 'precision': 0.8792235801581596,\n",
       " 'recall': 0.9745019920318725}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
