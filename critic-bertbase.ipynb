{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MDC 018 - Projeto Final",
   "id": "cc52547f1f6d38f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:57:00.490871Z",
     "start_time": "2024-12-08T13:56:55.261915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregando os dados de treinamento e teste\n",
    "train_critic = pd.read_csv(\"train_critic.csv\")\n",
    "\n",
    "test_critic = pd.read_csv(\"test_critic.csv\")"
   ],
   "id": "4ae38f923387d40",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:57:00.532881Z",
     "start_time": "2024-12-08T13:57:00.503391Z"
    }
   },
   "cell_type": "code",
   "source": "train_critic",
   "id": "23a9512718c1f945",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Show  Sentiment  \\\n",
       "0                                         Bodyguard          1   \n",
       "1                                           Mad Men          0   \n",
       "2      1971: The Year That Music Changed Everything          1   \n",
       "3                                    Six Feet Under          1   \n",
       "4                                     Pieces of Her          0   \n",
       "...                                             ...        ...   \n",
       "11827                              Freaks and Geeks          1   \n",
       "11828                                The Gilded Age          1   \n",
       "11829                                 Joe vs Carole          1   \n",
       "11830                                Rick and Morty          1   \n",
       "11831                               Y: The Last Man          1   \n",
       "\n",
       "                                                  Review  \n",
       "0      This has been a brilliant, compulsive, five-st...  \n",
       "1      With each new season, I try to remind myself t...  \n",
       "2      Here's one of the most all-encompassing and st...  \n",
       "3      To me, it was one of the most clever, funny, s...  \n",
       "4      Well acted and highly suspenseful, the eight-p...  \n",
       "...                                                  ...  \n",
       "11827  Freaks and Geeks boasts an extremely talented ...  \n",
       "11828  It's a period piece set in 1882 New York that ...  \n",
       "11829  McKinnon and her co-producers must be credited...  \n",
       "11830  As season openers go, this is a really solid e...  \n",
       "11831  Once the show moves past its been-there, watch...  \n",
       "\n",
       "[11832 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bodyguard</td>\n",
       "      <td>1</td>\n",
       "      <td>This has been a brilliant, compulsive, five-st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mad Men</td>\n",
       "      <td>0</td>\n",
       "      <td>With each new season, I try to remind myself t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1971: The Year That Music Changed Everything</td>\n",
       "      <td>1</td>\n",
       "      <td>Here's one of the most all-encompassing and st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Six Feet Under</td>\n",
       "      <td>1</td>\n",
       "      <td>To me, it was one of the most clever, funny, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pieces of Her</td>\n",
       "      <td>0</td>\n",
       "      <td>Well acted and highly suspenseful, the eight-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11827</th>\n",
       "      <td>Freaks and Geeks</td>\n",
       "      <td>1</td>\n",
       "      <td>Freaks and Geeks boasts an extremely talented ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11828</th>\n",
       "      <td>The Gilded Age</td>\n",
       "      <td>1</td>\n",
       "      <td>It's a period piece set in 1882 New York that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11829</th>\n",
       "      <td>Joe vs Carole</td>\n",
       "      <td>1</td>\n",
       "      <td>McKinnon and her co-producers must be credited...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11830</th>\n",
       "      <td>Rick and Morty</td>\n",
       "      <td>1</td>\n",
       "      <td>As season openers go, this is a really solid e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11831</th>\n",
       "      <td>Y: The Last Man</td>\n",
       "      <td>1</td>\n",
       "      <td>Once the show moves past its been-there, watch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11832 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Verificação de balanceamento:",
   "id": "8770f4295929a95f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:57:01.401523Z",
     "start_time": "2024-12-08T13:57:01.391149Z"
    }
   },
   "cell_type": "code",
   "source": "train_critic['Sentiment'].value_counts()\n",
   "id": "70acdc20acc9f9ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "1    9995\n",
       "0    1837\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ambos conjuntos estão fortemente desbalanceados.",
   "id": "6f721a20f344e0e7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Predição de sentimento\n",
    "\n",
    "Conjunto train_critic"
   ],
   "id": "bf1b39a390a7896a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:57:09.014070Z",
     "start_time": "2024-12-08T13:57:01.492997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Separação entre conjunto de treino e validação\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Remove NAs\n",
    "train_critic.dropna(subset=['Review'], inplace=True)\n",
    "\n",
    "(train_critic_df, val_critic_df) = train_test_split(train_critic, test_size=0.2)\n",
    "train_critic_df['Sentiment'].value_counts()"
   ],
   "id": "ce428f576e08bf33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment\n",
       "1    8005\n",
       "0    1459\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:57:09.123679Z",
     "start_time": "2024-12-08T13:57:09.109755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Calcular os pesos para as classes\n",
    "classes = train_critic['Sentiment'].unique()\n",
    "weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array(classes),\n",
    "    y=train_critic['Sentiment']\n",
    ")\n",
    "\n",
    "class_weights = dict(zip(classes, weights))\n",
    "class_weights"
   ],
   "id": "b8ed964bb5a5cffc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.5918459229614808, 0: 3.221949891067538}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:57:09.221740Z",
     "start_time": "2024-12-08T13:57:09.214720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val_critic_texts = val_critic_df[\"Review\"].tolist()\n",
    "val_critic_labels = val_critic_df[\"Sentiment\"].tolist()"
   ],
   "id": "354789f5fd35f1a7",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:57:32.485206Z",
     "start_time": "2024-12-08T13:57:09.300526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from transformers import pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_balanced_accuracy(model, tokenizer, texts, labels):\n",
    "    classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "    predictions = []\n",
    "\n",
    "    for text in texts:\n",
    "        result = classifier(text)\n",
    "        label = int(result[0][\"label\"].split(\"_\")[-1])\n",
    "        predictions.append(label)\n",
    "    return round(float(balanced_accuracy_score(labels, predictions)),2)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(trainer, dataset, label_names=None, cmap=\"Blues\"):\n",
    "    predictions_output = trainer.predict(dataset)\n",
    "    logits = predictions_output.predictions\n",
    "    labels = predictions_output.label_ids\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    cm = confusion_matrix(labels, predictions,  normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_names)\n",
    "    disp.plot(cmap=cmap, values_format=\".2f\")\n",
    "    plt.show()\n",
    "    return cm"
   ],
   "id": "e82dd0f551e04a3f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p.moura\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:57:47.402875Z",
     "start_time": "2024-12-08T13:57:32.493218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer, Trainer, TrainingArguments\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "\n",
    "model_name = \"google-bert/bert-base-cased\"  # Ou outro checkpoint pré-treinado\n",
    "num_labels = 2  # Número de classes no seu problema\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# Supondo que 'labels' contenha todos os rótulos do conjunto de treinamento\n",
    "labels = train_critic['Sentiment']  # Altere para acessar os rótulos no seu dataset"
   ],
   "id": "819b4a2c2da9f91b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\p.moura\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\p.moura\\.cache\\huggingface\\hub\\models--google-bert--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:57:52.032640Z",
     "start_time": "2024-12-08T13:57:47.427829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)  # Converta para um tensor PyTorch\n",
    "import torch.nn as nn\n",
    "\n",
    "#tokeniza os datasets\n",
    "train_encodings = tokenizer(train_critic_df['Review'].tolist(), truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(list(val_critic_df['Review']), truncation=True, padding=True, max_length=128)"
   ],
   "id": "8796e1cbb4c7cb39",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:57:52.251589Z",
     "start_time": "2024-12-08T13:57:52.244833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, class_weights, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        # Define a função de perda com os pesos de classe\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ],
   "id": "97af58ea1357abe7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T13:57:53.617191Z",
     "start_time": "2024-12-08T13:57:52.467967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import evaluate\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = metric.compute(predictions=predictions, references=labels)\n",
    "    return accuracy\n",
    "\n",
    "def compute_metrics_balanced(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Calcular acurácia balanceada\n",
    "    balanced_acc = balanced_accuracy_score(labels, predictions)\n",
    "\n",
    "    return {\"balanced_accuracy\": balanced_acc}"
   ],
   "id": "8eaa914b00217cb",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T17:45:55.329080Z",
     "start_time": "2024-12-08T13:57:54.022767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_critic_bertsmall\",\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,               # Carregar o melhor modelo ao final\n",
    "    metric_for_best_model=\"balanced_accuracy\", # Métrica para determinar o melhor modelo\n",
    "    save_strategy=\"epoch\",                     # Salvar checkpoints no final de cada época\n",
    "    save_total_limit=1,                        # Limitar os checkpoints a 1 para economizar espaço\n",
    "    greater_is_better=True                     # Se maior métrica significa melhor modelo\n",
    ")\n",
    "train_critic_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask'],\n",
    "    'labels': list(train_critic_df['Sentiment'])\n",
    "})\n",
    "\n",
    "val_critic_dataset = Dataset.from_dict({\n",
    "    'input_ids': val_encodings['input_ids'],\n",
    "    'attention_mask': val_encodings['attention_mask'],\n",
    "    'labels': list(val_critic_df['Sentiment'])\n",
    "})\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_critic_dataset,\n",
    "    eval_dataset=val_critic_dataset,\n",
    "    class_weights=class_weights,\n",
    "    compute_metrics=compute_metrics_balanced\n",
    ")\n",
    "trainer.train()"
   ],
   "id": "8676efdef42015b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9464' max='9464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9464/9464 3:47:56, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>0.685884</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.701973</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.684806</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.700300</td>\n",
       "      <td>0.691205</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.684975</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.692800</td>\n",
       "      <td>0.685839</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>0.684609</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.688500</td>\n",
       "      <td>0.683472</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9464, training_loss=0.6932627693234312, metrics={'train_runtime': 13679.7829, 'train_samples_per_second': 5.535, 'train_steps_per_second': 0.692, 'total_flos': 2918066048352000.0, 'train_loss': 0.6932627693234312, 'epoch': 8.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T17:47:40.677443Z",
     "start_time": "2024-12-08T17:45:55.535456Z"
    }
   },
   "cell_type": "code",
   "source": "get_balanced_accuracy(model, tokenizer, val_critic_texts, val_critic_labels)",
   "id": "df42c676c2650f5e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T17:49:25.340211Z",
     "start_time": "2024-12-08T17:47:40.838418Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate()",
   "id": "29b960156cb67976",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6858835816383362,\n",
       " 'eval_balanced_accuracy': 0.5,\n",
       " 'eval_runtime': 104.4906,\n",
       " 'eval_samples_per_second': 22.653,\n",
       " 'eval_steps_per_second': 2.833,\n",
       " 'epoch': 8.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T17:51:10.870291Z",
     "start_time": "2024-12-08T17:49:25.511053Z"
    }
   },
   "cell_type": "code",
   "source": "plot_confusion_matrix(trainer,val_critic_dataset)",
   "id": "8b63c58babb57a90",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Teste",
   "id": "1485884af37e1eef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T03:21:32.253372Z",
     "start_time": "2024-12-09T03:20:37.871178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_critic_texts = test_critic[\"Review\"].tolist()\n",
    "test_critic_labels = test_critic[\"Sentiment\"].tolist()\n",
    "get_balanced_accuracy(model, tokenizer, test_critic_texts, test_critic_labels)"
   ],
   "id": "910e80c4f7cc8101",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m test_critic_texts \u001B[38;5;241m=\u001B[39m test_critic[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReview\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m      2\u001B[0m test_critic_labels \u001B[38;5;241m=\u001B[39m test_critic[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSentiment\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m----> 3\u001B[0m \u001B[43mget_balanced_accuracy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_critic_texts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_critic_labels\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[7], line 10\u001B[0m, in \u001B[0;36mget_balanced_accuracy\u001B[1;34m(model, tokenizer, texts, labels)\u001B[0m\n\u001B[0;32m      7\u001B[0m predictions \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m texts:\n\u001B[1;32m---> 10\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mclassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(result[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m     12\u001B[0m     predictions\u001B[38;5;241m.\u001B[39mappend(label)\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:159\u001B[0m, in \u001B[0;36mTextClassificationPipeline.__call__\u001B[1;34m(self, inputs, **kwargs)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;124;03mClassify the text(s) given as inputs.\u001B[39;00m\n\u001B[0;32m    126\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001B[39;00m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    158\u001B[0m inputs \u001B[38;5;241m=\u001B[39m (inputs,)\n\u001B[1;32m--> 159\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001B[39;00m\n\u001B[0;32m    161\u001B[0m _legacy \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_k\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\transformers\\pipelines\\base.py:1302\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1294\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[0;32m   1295\u001B[0m         \u001B[38;5;28miter\u001B[39m(\n\u001B[0;32m   1296\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1299\u001B[0m         )\n\u001B[0;32m   1300\u001B[0m     )\n\u001B[0;32m   1301\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1302\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\transformers\\pipelines\\base.py:1309\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[1;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[0;32m   1307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[0;32m   1308\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[1;32m-> 1309\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1310\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[0;32m   1311\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\transformers\\pipelines\\base.py:1209\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[1;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[0;32m   1207\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[0;32m   1208\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m-> 1209\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1210\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m   1211\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:190\u001B[0m, in \u001B[0;36mTextClassificationPipeline._forward\u001B[1;34m(self, model_inputs)\u001B[0m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39msignature(model_forward)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    189\u001B[0m     model_inputs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_cache\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1668\u001B[0m, in \u001B[0;36mBertForSequenceClassification.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1660\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1661\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001B[39;00m\n\u001B[0;32m   1662\u001B[0m \u001B[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001B[39;00m\n\u001B[0;32m   1663\u001B[0m \u001B[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001B[39;00m\n\u001B[0;32m   1664\u001B[0m \u001B[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001B[39;00m\n\u001B[0;32m   1665\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1666\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[1;32m-> 1668\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1669\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1670\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1671\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1672\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1673\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1674\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1675\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1676\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1677\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1678\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1680\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m   1682\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(pooled_output)\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1142\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m   1135\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[0;32m   1138\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[0;32m   1139\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[0;32m   1140\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m-> 1142\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1143\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1144\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1145\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1146\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1147\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1148\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1149\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1150\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1151\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1152\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1153\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1154\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1155\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[0;32m    684\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[0;32m    685\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[0;32m    686\u001B[0m         hidden_states,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    692\u001B[0m         output_attentions,\n\u001B[0;32m    693\u001B[0m     )\n\u001B[0;32m    694\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 695\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    697\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    698\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    699\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    700\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    701\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    703\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    705\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    706\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:585\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    573\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    574\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    575\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    582\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m    583\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[0;32m    584\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 585\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    587\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    588\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    589\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    590\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    591\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    592\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    594\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:515\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    505\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[0;32m    506\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    507\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    513\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    514\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m--> 515\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    516\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    521\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    522\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    524\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[0;32m    525\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:408\u001B[0m, in \u001B[0;36mBertSdpaSelfAttention.forward\u001B[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[0;32m    406\u001B[0m     key_layer, value_layer \u001B[38;5;241m=\u001B[39m past_key_value\n\u001B[0;32m    407\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 408\u001B[0m     key_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtranspose_for_scores(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcurrent_states\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    409\u001B[0m     value_layer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtranspose_for_scores(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalue(current_states))\n\u001B[0;32m    410\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_cross_attention:\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32m~\\.virtualenvs\\mdc-projeto-final\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T03:21:32.328929800Z",
     "start_time": "2024-11-23T18:04:44.638787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_encodings = tokenizer(list(test_critic['Review']), truncation=True, padding=True, max_length=128)\n",
    "test_critic_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_encodings['input_ids'],\n",
    "    'attention_mask': test_encodings['attention_mask'],\n",
    "    'labels': list(test_critic['Sentiment'])\n",
    "})\n",
    "plot_confusion_matrix(trainer,test_critic_dataset)"
   ],
   "id": "f8d76325308021bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.65478842, 0.34521158],\n",
       "       [0.11713147, 0.88286853]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
